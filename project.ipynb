{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XhATaaotWpYY"
   },
   "source": [
    "# Project\n",
    "\n",
    "Implementation of VO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YaFe_Ot-ziRV"
   },
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "executionInfo": {
     "elapsed": 231,
     "status": "error",
     "timestamp": 1612557788001,
     "user": {
      "displayName": "Taeyoung Lee",
      "photoUrl": "",
      "userId": "07906618747313337531"
     },
     "user_tz": 300
    },
    "id": "XOGSROrK6oGt",
    "outputId": "201bf5ab-4d81-436e-cb82-4c62e1feaf32"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import scipy.signal\n",
    "import scipy.linalg\n",
    "import mae6292.tools as mae6292\n",
    "import importlib\n",
    "\n",
    "from mae6292.imshow import cv2_imshow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SEUEyf2dPM-4"
   },
   "source": [
    "# VO - KITTI\n",
    "\n",
    "The following codes perform VO for KITTI dataset, for the first 10 frames.\n",
    "\n",
    "## Boostrapping\n",
    "\n",
    "Bootstrapping to initilize VO has been implemented by\n",
    "```\n",
    "keypoints0, p_W0, R1, T1 = mae6292.VO_bootstrap(img0, img1, K, display = False)   \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#open a new window for plot\n",
    "#qt can be installed by running `pip install pyside6`\n",
    "%matplotlib qt \n",
    "\n",
    "# load K and first two images\n",
    "K = np.loadtxt('KITTI/K.txt')\n",
    "img0 = cv2.imread('KITTI/000000.png', cv2.IMREAD_GRAYSCALE)\n",
    "img1 = cv2.imread('KITTI/000002.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# PARAMETERS\n",
    "param_bootstrap = {\n",
    "    # keypoints\n",
    "    'W_harris_patch' : 4, # size of harris patch\n",
    "    'kappa_harris' : 0.08, # kappa for harris score\n",
    "    'N_keypoint' : 2000, # number of keypoints to be detected\n",
    "    'W_nms' : 8, # patch size for non-maximum supression\n",
    "    # KLT\n",
    "    'W_KLT' : 4, # patch size for KLT\n",
    "    'tol_KLT_bidir' : 1, # tolerence of bidirectional error\n",
    "    # find essential matrix\n",
    "    'tol_E' : 1, # tolerence for epipolar line distance\n",
    "    'tol_E_RANSAC_prob' : 0.99, # eseential matrix RANSAC probability\n",
    "    # triangulation\n",
    "    'tol_TRI_mu' : 1e-3, # tolerence for the singular value ratio\n",
    "    'tol_TRI_rep' : 1 # tolerence for the reprojection error\n",
    "}\n",
    "\n",
    "keypoints0, p_W0, R1, T1 = mae6292.VO_bootstrap(img0, img1, K, param_bootstrap, display = True)   \n",
    "\n",
    "print('N_keypoints0=',len(keypoints0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Localization and Mapping\n",
    "\n",
    "\n",
    "For the first 10 frames, the sequential process for localization and mapping has been implemented by\n",
    "```\n",
    "    R, T, S, C, fig = mae6292.VO_localization_mapping(i_frame, K, img, img_pre, S_pre, C_pre, display_process=True)\n",
    "```\n",
    "Each frame is saved under the folder `KITTI_output`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#open a new window for plot\n",
    "%matplotlib qt\n",
    "importlib.reload(mae6292)\n",
    "\n",
    "param = {\n",
    "    # keypoints\n",
    "    'W_harris_patch' : 4, # size of harris patch\n",
    "    'kappa_harris' : 0.08, # kappa for harris score\n",
    "    'N_keypoint' : 2000, # number of keypoints to be detected\n",
    "    'W_nms' : 8, # patch size for non-maximum supression\n",
    "    # KLT\n",
    "    'W_KLT' : 4, # patch size for KLT\n",
    "    'tol_KLT_bidir' : 1, # tolerence of bidirectional error\n",
    "    # triangulation\n",
    "    'tol_TRI_mu' : 1e-3, # tolerence for the singular value ratio\n",
    "    'tol_TRI_rep' : 0.5, # tolerence for the reprojection error\n",
    "    # mapping\n",
    "    'tol_keypoints_new' : 18 # new keypoints should be district from the tracked keypoints by this distance\n",
    "} # up to 1000 \n",
    "\n",
    "# iniitlize iteration using img0\n",
    "img_pre = img0\n",
    "S_pre = mae6292.state(keypoints0, p_W0, [np.zeros((3,1))])\n",
    "C_pre = mae6292.candidate([],[],[],[])\n",
    "\n",
    "# number of frames to process\n",
    "N_frames = 10\n",
    "display_process = True\n",
    "\n",
    "# variables to save the vehicle location and the keypoints in the W-frame \n",
    "T_W = np.zeros((3,N_frames+1))\n",
    "p_W = p_W0\n",
    "\n",
    "for i_frame in range(1,N_frames+1):\n",
    "    \n",
    "    print('i_frame=',i_frame)\n",
    "\n",
    "    # VO localization and mapping\n",
    "    img = cv2.imread(\"KITTI/{:06d}.png\".format(i_frame),cv2.IMREAD_GRAYSCALE)\n",
    "    img_rgb = cv2.cvtColor(cv2.imread(\"KITTI/{:06d}.png\".format(i_frame)), cv2.COLOR_BGR2RGB)\n",
    "    R, T, S, C, fig = mae6292.VO_localization_mapping(i_frame, img, img_rgb, img_pre, S_pre, C_pre, K, param, display_process)\n",
    "    img_pre, S_pre, C_pre = img, S, C\n",
    "\n",
    "    # save figure \n",
    "    if display_process:\n",
    "        fig.savefig(\"KITTI_output/{:06d}.png\".format(i_frame))\n",
    "        # !!!NOTE!!!:\n",
    "        # when N_frames is large, uncomment the following to avoid generating too many figures in your screeen\n",
    "        # plt.close(fig)\n",
    "\n",
    "    # save the vehicle location and the distinct keypoints \n",
    "    T_W[:,i_frame] = (-R.T@T).flatten()\n",
    "    p_W_dist = scipy.spatial.distance.cdist( S.p_W.T, p_W.T , 'euclidean')\n",
    "    index_distinct = np.where( np.min(p_W_dist, axis=1) > 3 )[0]\n",
    "    p_W = np.append(p_W, S.p_W[:,index_distinct], axis=1)\n",
    "\n",
    "    # print pose\n",
    "    print('R=',R)\n",
    "    print('T_W=',(-R.T@T).flatten())\n",
    "    print(' ')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Trajectory Map\n",
    "\n",
    "The following codes visualize the vehicle trajectory and the keypoints in the W-frame. \n",
    "\n",
    "(You may need to adjust th eaxis limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes(projection = '3d')\n",
    "ax.plot(T_W[0,:], T_W[1,:], T_W[2,:], 'b')\n",
    "ax.scatter(p_W[0,:], p_W[1,:], p_W[2,:], s=1, c='r', marker='o')\n",
    "ax.set_xlim(-10,20)\n",
    "ax.set_zlim(-2,20)\n",
    "ax.set_xlabel('x',fontsize=6)\n",
    "ax.set_ylabel('y',fontsize=6)\n",
    "ax.set_zlabel('z',fontsize=6)\n",
    "ax.view_init(elev=0., azim=-90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Video\n",
    "\n",
    "The output images can be converted into a video as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array = []\n",
    "\n",
    "for i_frame in range(1,N_frames):\n",
    "    filename = \"KITTI_output/{:06d}.png\".format(i_frame)\n",
    "    img = cv2.imread(filename)\n",
    "    img_array.append(img)\n",
    "\n",
    "height, width, layers = img.shape\n",
    "size = (width,height)\n",
    "\n",
    "fps = 3\n",
    "codec = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('KITTI_output/KITTI.mp4',codec, fps, size)\n",
    " \n",
    "for i in range(len(img_array)):\n",
    "    out.write(img_array[i])\n",
    "\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems 1 and 2\n",
    "\n",
    "Follow the directions in `project_prob1.ipynb`and `project_prob2.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "YaFe_Ot-ziRV"
   ],
   "name": "image_filtering.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
