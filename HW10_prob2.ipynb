{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XhATaaotWpYY"
   },
   "source": [
    "# Homework \\#10 - Problem 2\n",
    "\n",
    "Implementation of VO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1nvWOLW-YUMv"
   },
   "source": [
    "## Google Colab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 257,
     "status": "ok",
     "timestamp": 1612557785555,
     "user": {
      "displayName": "Taeyoung Lee",
      "photoUrl": "",
      "userId": "07906618747313337531"
     },
     "user_tz": 300
    },
    "id": "f7eDiZtVX6DM",
    "outputId": "79b61644-4fd1-4046-c98d-fbc6a8a3d93a"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "\n",
    "# drive.mount('/content/drive')\n",
    "# %cd '/content/drive/MyDrive/Colab Notebooks'\n",
    "\n",
    "# import numpy as np\n",
    "# import cv2\n",
    "# import matplotlib.pyplot as plt\n",
    "# import math\n",
    "# import scipy.signal\n",
    "# import scipy.linalg\n",
    "# import importlib\n",
    "# import mae6292.tools as mae6292\n",
    "\n",
    "# from google.colab.patches import cv2_imshow\n",
    "# from google.colab import files as FILE\n",
    "# import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YaFe_Ot-ziRV"
   },
   "source": [
    "## Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "executionInfo": {
     "elapsed": 231,
     "status": "error",
     "timestamp": 1612557788001,
     "user": {
      "displayName": "Taeyoung Lee",
      "photoUrl": "",
      "userId": "07906618747313337531"
     },
     "user_tz": 300
    },
    "id": "XOGSROrK6oGt",
    "outputId": "201bf5ab-4d81-436e-cb82-4c62e1feaf32"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import scipy.signal\n",
    "import scipy.linalg\n",
    "import mae6292.tools as mae6292\n",
    "import importlib\n",
    "\n",
    "from mae6292.imshow import cv2_imshow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2 (80pt)\n",
    "\n",
    "Now, we are going to perform VO for an arbitrary data set. Perform VO as descriubed in Problem 1, and generate the similar outcomes. You can use all of your knowledge learned during this class, and feel free to modify any part of the code.\n",
    "\n",
    "\n",
    "## Dataset \n",
    "\n",
    "There are a lot benchmark datasets. **It is expected that everyones use a DIFFRENT set of data.**\n",
    "\n",
    "For example,\n",
    "\n",
    "* Awesome SLAM datasets https://github.com/youngguncho/awesome-slam-datasets\n",
    "* EuRoC https://projects.asl.ethz.ch/datasets/doku.php?id=kmavvisualinertialdatasets\n",
    "* MVSEC https://daniilidis-group.github.io/mvsec/\n",
    "* Blackbird https://github.com/mit-fast/Blackbird-Dataset\n",
    "* UZH-FPV https://fpv.ifi.uzh.ch\n",
    "* Computer Vison Group, TMU https://vision.in.tum.de/data/datasets/mono-dataset\n",
    "* KITTI https://github.com/utiasSTARS/pykitti (choose a trajectory different from the particular one discussed in class)\n",
    "\n",
    "Instead of the above, you are welcome to record your own video.\n",
    "\n",
    "1. Record a video in a place where many features are availalbe. Make the resolution similar with the KITTI dataset (1241x376) or the parking lot dataset (640x480)\n",
    "\n",
    "2. You can extract image frames from a video by\n",
    "[https://www.geeksforgeeks.org/extract-images-from-video-in-python/](https://www.geeksforgeeks.org/extract-images-from-video-in-python/)\n",
    "\n",
    "3. Recall in HW#2, we did camera calibration to conmpute `K`. A method to calibrate camera with multiple images and to undistort image are availalbe at \n",
    "[Camera Calibration](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_calib3d/py_calibration/py_calibration.html)\n",
    "\n",
    "\n",
    "\n",
    "## Tips\n",
    "\n",
    "* First perform bootstrapping and see if the triangulated points make sense in the world frame. We need sufficiently large baseline to be successful. If needed the bootstratpping can be done with the first and the third or later.\n",
    "\n",
    "* Then, try localization and mapping using the similar parameters for the first 10 frames. Tune the parameters before trying more frames.\n",
    "\n",
    "* For robust triangulation, you can implement further error checking to discards keypoints with negative depts or kepoints too far away.\n",
    "\n",
    "More specifically, the following if statement in `mae6292.VO_localization_mapping` can be updated with additional error check.\n",
    "\n",
    "```\n",
    "# If the triangulated p_W is inlier then the corresponding keypoint is added to the state\n",
    "if index_pW_inliers.shape[0] > 0:\n",
    "    index_C_pre_matched_inliers.append(i)\n",
    "    S_keypoints.append((C_p_i[1], C_p_i[0]))\n",
    "    S_p_W = np.concatenate( (S_p_W, p_W_i), axis=1)\n",
    "# Otherwise save it with the prior history as a tracked, continuing candidate\n",
    "else:\n",
    "    index_C_pre_matched_outliers.append(i)\n",
    "    C_keypoints.append((C_p_i[1], C_p_i[0]))\n",
    "    C_keypoints_org.append(C_pre.keypoints_org[i])\n",
    "    C_R_org.append(C_pre.R_org[i])\n",
    "    C_T_org.append(C_pre.T_org[i])\n",
    "```\n",
    "\n",
    "* Once you make any changed to `mae6292` functions in your text editor, execute `importlib.reload(mae6292)` so that your updates are reloaded to Jupyter.\n",
    "\n",
    "## How To Submit\n",
    "\n",
    "* Write a short description about how your obtained the data.\n",
    "* Generate the following outcomes similar with Problem 1.\n",
    "    1. `prob2_bootstrap.png`: image showing the results of bootstrapping\n",
    "    2. `prob2.mp4`: video showing the results of localization and mapping at each frame\n",
    "    3. `prob2_map.png`: image showing the complete trajectory map\n",
    "* Describe your approaches that were implemented to tune the paramters and to update the code. \n",
    "* Discuss what was successful and what was not successful.\n",
    "* Discuss what should be done to improve your results.\n",
    "* Finally, upload your video to **YouTube** and specify the link.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "YaFe_Ot-ziRV"
   ],
   "name": "image_filtering.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
